{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that some of the raw data files are very large\n",
    "# these very large files are located in a gitignored directory.\n",
    "\n",
    "# data with site predictions\n",
    "export_data_csv = \"../00_Data/cleaned_data/data_with_site_predictions.csv\"\n",
    "\n",
    "# file containing the desired columns for the visualizations\n",
    "from viz_columns import viz_columns\n",
    "\n",
    "# export for visualizations\n",
    "viz_data_csv = \"../04_Resources/data/superfund_data.csv\"\n",
    "viz_data_json = \"../04_Resources/data/superfund_data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the cleaned, merged data with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220423 entries, 0 to 220422\n",
      "Columns: 242 entries, fips_block_group to score_prediction\n",
      "dtypes: float64(228), int64(1), object(13)\n",
      "memory usage: 407.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(export_data_csv)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of columns for manual database generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_columns = data_df.columns\n",
    "\n",
    "db_dict = {}\n",
    "for column in db_columns:\n",
    "    column_type = data_df[column].dtype\n",
    "    if column_type == 'float64':\n",
    "        db_dict[column] = 'FLOAT'\n",
    "    elif column_type == 'O':\n",
    "        db_dict[column] = 'VARCHAR'\n",
    "    elif column_type == 'int64':\n",
    "        db_dict[column] = 'BIGINT'\n",
    "    else:\n",
    "        print(f\"Unexpected dtype on column {column}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sql commands to a file in case we need to set up the database manually\n",
    "f = open(\"sql_commands.txt\", \"w\")\n",
    "hasTextBeenWritten = False\n",
    "f.write(\"-- Create table for data import: \\n\")\n",
    "f.write(\"CREATE TABLE superfund_data_table ( \\n\")\n",
    "for i in db_dict:\n",
    "    if hasTextBeenWritten:\n",
    "        f.write(\",\\n\")\n",
    "    f.write(f\"\\t{i}\\t\\t\\t{db_dict[i]}\")\n",
    "    hasTextBeenWritten = True\n",
    "f.write(\"\\n);\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Full Dataset into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to database\n",
    "rds_connection_string = \"postgres:postgres@localhost:5432/project_3_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['superfund_data_table']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the dataframe into the database\n",
    "\n",
    "# use this to add new data\n",
    "# data_df.to_sql(name='superfund_data_table', con=engine, if_exists='append', index=False)\n",
    "\n",
    "# use this to overwrite existing\n",
    "data_df.to_sql(name='superfund_data_table', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data for Visualizations from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of desired columns and make sure the column names are lowercase\n",
    "desired_columns = [x.lower() for x in viz_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved \"address\".\n",
      "Retrieved \"city\".\n",
      "Retrieved \"latitude\".\n",
      "Retrieved \"longitude\".\n",
      "Retrieved \"site_score\".\n",
      "Retrieved \"site_text\".\n",
      "Retrieved \"state_name\".\n",
      "Retrieved \"county_name\".\n",
      "Retrieved \"tract\".\n",
      "Retrieved \"block_group\".\n",
      "Retrieved \"tot_population_cen_2010\".\n",
      "Retrieved \"hispanic_cen_2010\".\n",
      "Retrieved \"nh_blk_alone_cen_2010\".\n",
      "Retrieved \"nh_aian_alone_cen_2010\".\n",
      "Retrieved \"nh_asian_alone_cen_2010\".\n",
      "Retrieved \"nh_nhopi_alone_cen_2010\".\n",
      "Retrieved \"nh_sor_alone_cen_2010\".\n",
      "Retrieved \"college_acs_09_13\".\n",
      "Retrieved \"no_health_ins_acs_09_13\".\n",
      "Retrieved \"med_hhd_inc_bg_acs_09_13\".\n",
      "Retrieved \"aggregate_hh_inc_acs_09_13\".\n",
      "Retrieved \"tot_vacant_units_cen_2010\".\n",
      "Retrieved \"renter_occp_hu_cen_2010\".\n",
      "Retrieved \"owner_occp_hu_cen_2010\".\n",
      "Retrieved \"no_plumb_acs_09_13\".\n",
      "Retrieved \"med_house_value_bg_acs_09_13\".\n",
      "Retrieved \"pct_hispanic_cen_2010\".\n",
      "Retrieved \"pct_nh_blk_alone_cen_2010\".\n",
      "Retrieved \"pct_nh_aian_alone_cen_2010\".\n",
      "Retrieved \"pct_nh_asian_alone_cen_2010\".\n",
      "Retrieved \"pct_nh_nhopi_alone_cen_2010\".\n",
      "Retrieved \"pct_nh_sor_alone_cen_2010\".\n",
      "Retrieved \"pct_not_hs_grad_acs_09_13\".\n",
      "Retrieved \"pct_no_health_ins_acs_09_13\".\n",
      "Retrieved \"pct_vacant_units_cen_2010\".\n",
      "Retrieved \"pct_renter_occp_hu_cen_2010\".\n",
      "Retrieved \"pct_owner_occp_hu_cen_2010\".\n",
      "Retrieved \"pct_no_plumb_acs_09_13\".\n",
      "Retrieved \"site_probability\".\n",
      "Retrieved \"score_prediction\".\n"
     ]
    }
   ],
   "source": [
    "# create a blank dataframe to hold the viz data.\n",
    "viz_df = pd.DataFrame()\n",
    "\n",
    "# step through the list of viz columns and populate the viz dataframe.\n",
    "for x in desired_columns:\n",
    "    try:\n",
    "        viz = pd.read_sql_query(f\"select {x} from superfund_data_table\", con=engine)\n",
    "        viz_df[x] = viz[x]\n",
    "        print(f\"Retrieved \\\"{x}\\\".\")\n",
    "    except:\n",
    "        print(f\"Failed to retrieve \\\"{x}\\\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Visualization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "viz_df.to_csv(viz_data_csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to json\n",
    "viz_df.to_json(viz_data_json, orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
